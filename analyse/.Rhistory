# Linear model to assess factors
model <- lm(avg_latency_ms ~ mode + resolution + codec + source_device + fps_target,
data = device_performance)
summary(model)
# Verify device counts per run
device_performance %>%
count(run_id) %>%
head()
fps_list <- sort(unique(device_performance$fps_target))
for (current_fps in fps_list) {
p <- device_performance %>%
filter(fps_target == current_fps) %>%
ggplot(aes(x = model_name, y = avg_latency_ms, fill = mode)) +
geom_boxplot(alpha = 0.7, outlier.shape = NA) +
geom_jitter(position = position_jitterdodge(jitter.width = 0.1), size = 1, alpha = 0.5) +
facet_wrap(~resolution, scales = "free_y") +
labs(
title = paste("Performance Comparison at", current_fps, "FPS"),
subtitle = "Comparing Local vs. Offload execution across models",
x = "Model Name",
y = "Latency (ms)",
fill = "Mode"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p)
}
for (current_fps in fps_list) {
p <- device_performance %>%
filter(fps_target == current_fps) %>%
pivot_longer(cols = c(inference_ms, overhead_ms),
names_to = "component", values_to = "ms") %>%
ggplot(aes(x = mode, y = ms, fill = component)) +
geom_bar(stat = "summary", fun = "mean", position = "stack", width = 0.7) +
facet_grid(resolution ~ model_name) +
scale_fill_manual(
values = c("inference_ms" = "#27ae60", "overhead_ms" = "#e74c3c"),
labels = c("Inference", "Network/Transport Overhead")
) +
labs(
title = paste("Latency Breakdown at", current_fps, "FPS"),
subtitle = "Green = AI Work | Red = Network Tax",
x = "Execution Mode",
y = "Total End-to-End Latency (ms)",
fill = "Component"
) +
theme_minimal() +
theme(legend.position = "bottom")
print(p)
}
all_fps    <- sort(unique(device_performance$fps_target))
all_codecs <- unique(device_performance$codec)
all_tiers  <- sort(unique(device_performance$tier))
for (f in all_fps) {
for (c in all_codecs) {
for (t in all_tiers) {
plot_subset <- device_performance %>%
filter(fps_target == f, codec == c, tier == t)
if(nrow(plot_subset) == 0) next
# Latency plot
p_lat <- ggplot(plot_subset, aes(x = model_name, y = avg_latency_ms, fill = mode)) +
geom_bar(stat = "summary", fun = "mean", position = position_dodge(width = 0.8), width = 0.7) +
geom_jitter(position = position_dodge(width = 0.8), size = 1.2, alpha = 0.5) +
facet_wrap(~resolution, scales = "free_y") +
scale_fill_manual(values = c("Local" = "#2c3e50", "Offload" = "#27ae60")) +
labs(title = paste("Latency |", f, "FPS |", c, "|", t),
y = "Avg Latency (ms)", x = "Model") +
theme_minimal()
# Drop rate plot
p_drop <- ggplot(plot_subset, aes(x = model_name, y = drop_rate_pct, fill = mode)) +
geom_bar(stat = "summary", fun = "mean", position = position_dodge(width = 0.8), width = 0.7) +
geom_jitter(position = position_dodge(width = 0.8), size = 1, alpha = 0.4) +
facet_wrap(~resolution) +
scale_fill_manual(values = c("Local" = "#34495e", "Offload" = "#d35400")) +
scale_y_continuous(limits = c(0, 100)) +
labs(title = paste("Drop Rate |", f, "FPS |", c, "|", t),
y = "Drop Rate (%)", x = "Model") +
theme_minimal()
# Detection plot
p_det <- ggplot(plot_subset, aes(x = model_name, y = avg_detections, fill = mode)) +
geom_bar(stat = "summary", fun = "mean", position = position_dodge(width = 0.8), width = 0.7) +
geom_jitter(position = position_dodge(width = 0.8), size = 1.2, alpha = 0.5) +
facet_wrap(~resolution) +
scale_fill_manual(values = c("Local" = "#2c3e50", "Offload" = "#8e44ad")) +
labs(
title = paste("Avg Detections |", f, "FPS"),
subtitle = paste("Codec:", c, "| Quality Tier:", t),
x = "AI Model",
y = "Avg Detection Count per Frame",
fill = "Execution Mode"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Print plots
print(p_lat)
print(p_drop)
print(p_det)
# Save plots
file_base <- paste0("fps", f, "_", c, "_", t)
ggsave(paste0("plots/latency_", file_base, ".png"), p_lat, width = 10, height = 6)
ggsave(paste0("plots/drops_", file_base, ".png"), p_drop, width = 10, height = 6)
ggsave(paste0("plots_detections/det_", file_base, ".png"), p_det, width = 10, height = 6)
message("Saved plots for: ", file_base)
}
}
}
library(tidyverse)
library(vroom)
# Create output directories
if (!dir.exists("plots")) dir.create("plots")
if (!dir.exists("plots_detections")) dir.create("plots_detections")
# Load all CSV files from logs directory
files <- list.files("logs/", pattern = "\\.csv$", full.names = TRUE)
df_raw <- vroom(files, id = "filepath", show_col_types = FALSE) %>%
mutate(
fps_target = as.numeric(str_extract(filepath, "\\d+(?=fps)")),
run_id = basename(filepath)
)
# Aggregate to device level (3 rows per run)
device_performance <- df_raw %>%
group_by(run_id, source_device) %>%
summarise(
# Metadata
mode           = first(mode),
model_name     = first(model_name),
codec          = first(codec),
tier           = first(tier),
resolution     = first(resolution),
fps_target     = first(fps_target),
# Latency metrics
avg_latency_ms = mean(total_latency_us, na.rm = TRUE) / 1000,
sd_latency_ms  = sd(total_latency_us, na.rm = TRUE) / 1000,
inference_ms   = mean(inference_time_us, na.rm = TRUE) / 1000,
overhead_ms    = avg_latency_ms - inference_ms,
# Drop rate metrics
actual_count   = n(),
expected_count = first(fps_target) * 30,
drop_rate_pct  = pmax(0, 1 - (actual_count / expected_count)) * 100,
# Detection metrics
avg_detections = mean(detection_count, na.rm = TRUE),
.groups = "drop"
)
# Mode comparison (Local vs Offload)
mode_comparison <- device_performance %>%
group_by(model_name, codec, tier, resolution, fps_target, mode) %>%
summarise(
mean_lat = mean(avg_latency_ms, na.rm = TRUE),
mean_drop = mean(drop_rate_pct, na.rm = TRUE),
.groups = "drop"
) %>%
pivot_wider(
names_from = mode,
values_from = c(mean_lat, mean_drop)
) %>%
mutate(
latency_improvement = mean_lat_Local - mean_lat_Offload,
drop_reduction = mean_drop_Local - mean_drop_Offload
)
# Linear model to assess factors
model <- lm(avg_latency_ms ~ mode + resolution + codec + source_device + fps_target,
data = device_performance)
summary(model)
# Verify device counts per run
device_performance %>%
count(run_id) %>%
head()
fps_list <- sort(unique(device_performance$fps_target))
for (current_fps in fps_list) {
p <- device_performance %>%
filter(fps_target == current_fps) %>%
ggplot(aes(x = model_name, y = avg_latency_ms, fill = mode)) +
geom_boxplot(alpha = 0.7, outlier.shape = NA) +
geom_jitter(position = position_jitterdodge(jitter.width = 0.1), size = 1, alpha = 0.5) +
facet_wrap(~resolution, scales = "free_y") +
labs(
title = paste("Performance Comparison at", current_fps, "FPS"),
subtitle = "Comparing Local vs. Offload execution across models",
x = "Model Name",
y = "Latency (ms)",
fill = "Mode"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p)
}
for (current_fps in fps_list) {
p <- device_performance %>%
filter(fps_target == current_fps) %>%
pivot_longer(cols = c(inference_ms, overhead_ms),
names_to = "component", values_to = "ms") %>%
ggplot(aes(x = mode, y = ms, fill = component)) +
geom_bar(stat = "summary", fun = "mean", position = "stack", width = 0.7) +
facet_grid(resolution ~ model_name) +
scale_fill_manual(
values = c("inference_ms" = "#27ae60", "overhead_ms" = "#e74c3c"),
labels = c("Inference", "Network/Transport Overhead")
) +
labs(
title = paste("Latency Breakdown at", current_fps, "FPS"),
subtitle = "Green = AI Work | Red = Network Tax",
x = "Execution Mode",
y = "Total End-to-End Latency (ms)",
fill = "Component"
) +
theme_minimal() +
theme(legend.position = "bottom")
print(p)
}
all_fps    <- sort(unique(device_performance$fps_target))
all_codecs <- unique(device_performance$codec)
all_tiers  <- sort(unique(device_performance$tier))
for (f in all_fps) {
for (c in all_codecs) {
for (t in all_tiers) {
plot_subset <- device_performance %>%
filter(fps_target == f, codec == c, tier == t)
if(nrow(plot_subset) == 0) next
# Latency plot
p_lat <- ggplot(plot_subset, aes(x = model_name, y = avg_latency_ms, fill = mode)) +
geom_bar(stat = "summary", fun = "mean", position = position_dodge(width = 0.8), width = 0.7) +
geom_jitter(position = position_dodge(width = 0.8), size = 1.2, alpha = 0.5) +
facet_wrap(~resolution, scales = "free_y") +
scale_fill_manual(values = c("Local" = "#2c3e50", "Offload" = "#27ae60")) +
labs(title = paste("Latency |", f, "FPS |", c, "|", t),
y = "Avg Latency (ms)", x = "Model") +
theme_minimal()
# Drop rate plot
p_drop <- ggplot(plot_subset, aes(x = model_name, y = drop_rate_pct, fill = mode)) +
geom_bar(stat = "summary", fun = "mean", position = position_dodge(width = 0.8), width = 0.7) +
geom_jitter(position = position_dodge(width = 0.8), size = 1, alpha = 0.4) +
facet_wrap(~resolution) +
scale_fill_manual(values = c("Local" = "#34495e", "Offload" = "#d35400")) +
scale_y_continuous(limits = c(0, 100)) +
labs(title = paste("Drop Rate |", f, "FPS |", c, "|", t),
y = "Drop Rate (%)", x = "Model") +
theme_minimal()
# Detection plot
p_det <- ggplot(plot_subset, aes(x = model_name, y = avg_detections, fill = mode)) +
geom_bar(stat = "summary", fun = "mean", position = position_dodge(width = 0.8), width = 0.7) +
geom_jitter(position = position_dodge(width = 0.8), size = 1.2, alpha = 0.5) +
facet_wrap(~resolution) +
scale_fill_manual(values = c("Local" = "#2c3e50", "Offload" = "#8e44ad")) +
labs(
title = paste("Avg Detections |", f, "FPS"),
subtitle = paste("Codec:", c, "| Quality Tier:", t),
x = "AI Model",
y = "Avg Detection Count per Frame",
fill = "Execution Mode"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Print plots
print(p_lat)
print(p_drop)
print(p_det)
# Save plots
file_base <- paste0("fps", f, "_", c, "_", t)
ggsave(paste0("plots/latency_", file_base, ".png"), p_lat, width = 10, height = 6)
ggsave(paste0("plots/drops_", file_base, ".png"), p_drop, width = 10, height = 6)
ggsave(paste0("plots/det_", file_base, ".png"), p_det, width = 10, height = 6)
message("Saved plots for: ", file_base)
}
}
}
library(tidyverse)
library(vroom)
library(broom)
# Create output directories
if (!dir.exists("plots")) dir.create("plots")
# Load all CSV files from logs directory
files <- list.files("logs/", pattern = "\\.csv$", full.names = TRUE)
df_raw <- vroom(files, id = "filepath", show_col_types = FALSE) %>%
mutate(
fps_target = as.numeric(str_extract(filepath, "\\d+(?=fps)")),
run_id = basename(filepath)
)
# Aggregate to device level (3 rows per run)
device_performance <- df_raw %>%
group_by(run_id, source_device) %>%
summarise(
# Metadata
mode           = first(mode),
model_name     = first(model_name),
codec          = first(codec),
tier           = first(tier),
resolution     = first(resolution),
fps_target     = first(fps_target),
# Latency metrics
avg_latency_ms = mean(total_latency_us, na.rm = TRUE) / 1000,
sd_latency_ms  = sd(total_latency_us, na.rm = TRUE) / 1000,
inference_ms   = mean(inference_time_us, na.rm = TRUE) / 1000,
overhead_ms    = avg_latency_ms - inference_ms,
# Drop rate metrics
actual_count   = n(),
expected_count = first(fps_target) * 30,
drop_rate_pct  = pmax(0, 1 - (actual_count / expected_count)) * 100,
# Detection metrics
avg_detections = mean(detection_count, na.rm = TRUE),
.groups = "drop"
)
# Mode comparison (Local vs Offload)
mode_comparison <- device_performance %>%
group_by(model_name, codec, tier, resolution, fps_target, mode) %>%
summarise(
mean_lat = mean(avg_latency_ms, na.rm = TRUE),
mean_drop = mean(drop_rate_pct, na.rm = TRUE),
.groups = "drop"
) %>%
pivot_wider(
names_from = mode,
values_from = c(mean_lat, mean_drop)
) %>%
mutate(
latency_improvement = mean_lat_Local - mean_lat_Offload,
drop_reduction = mean_drop_Local - mean_drop_Offload
)
# Linear model to assess factors (latency)
model_latency <- lm(avg_latency_ms ~ mode + resolution + codec + source_device + fps_target,
data = device_performance)
summary(model_latency)
# Verify device counts per run
device_performance %>%
count(run_id) %>%
head()
# Run separate regressions for each FPS target
fps_list <- sort(unique(device_performance$fps_target))
drop_rate_models <- list()
drop_rate_summaries <- list()
for (current_fps in fps_list) {
cat("\n===========================================\n")
cat("FPS TARGET:", current_fps, "\n")
cat("===========================================\n\n")
# Filter data for this FPS
fps_data <- device_performance %>%
filter(fps_target == current_fps)
# Fit model with model_name as key predictor
model <- lm(drop_rate_pct ~ model_name + mode + resolution + codec + tier + source_device,
data = fps_data)
# Store model
drop_rate_models[[paste0("fps_", current_fps)]] <- model
# Print summary
print(summary(model))
# Extract model coefficients for comparison
coef_summary <- broom::tidy(model) %>%
filter(str_detect(term, "^model_name")) %>%
arrange(estimate)
drop_rate_summaries[[paste0("fps_", current_fps)]] <- coef_summary
cat("\n--- Model Performance Rankings ---\n")
print(coef_summary)
cat("\n")
}
# Combine all summaries for visualization
all_model_effects <- bind_rows(drop_rate_summaries, .id = "fps_config") %>%
mutate(
fps = as.numeric(str_extract(fps_config, "\\d+")),
model = str_remove(term, "^model_name")
)
# Plot model effects across FPS targets
ggplot(all_model_effects, aes(x = model, y = estimate, fill = as.factor(fps))) +
geom_col(position = position_dodge(width = 0.8), width = 0.7) +
geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error),
position = position_dodge(width = 0.8), width = 0.3) +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(
title = "Model Effect on Drop Rate by FPS Target",
subtitle = "Negative values = lower drop rate (better). Reference model excluded.",
x = "Model",
y = "Effect on Drop Rate (%)",
fill = "FPS Target"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Single model across all FPS with interaction terms
overall_model <- lm(drop_rate_pct ~ model_name * fps_target + mode + resolution + codec + tier + source_device,
data = device_performance)
cat("\n===========================================\n")
cat("OVERALL DROP RATE MODEL (ALL FPS)\n")
cat("===========================================\n\n")
print(summary(overall_model))
# Extract model-specific effects
model_effects <- broom::tidy(overall_model) %>%
filter(str_detect(term, "^model_name") & !str_detect(term, ":")) %>%
arrange(estimate)
cat("\n--- Overall Model Rankings (Main Effects) ---\n")
print(model_effects)
# ANOVA to test if model_name is significant predictor
cat("\n--- ANOVA: Model Name Significance ---\n")
print(anova(overall_model))
# Estimated marginal means for each model
cat("\n--- Predicted Drop Rates by Model (Averaged Across Conditions) ---\n")
model_predictions <- device_performance %>%
group_by(model_name) %>%
summarise(
mean_drop = mean(drop_rate_pct, na.rm = TRUE),
sd_drop = sd(drop_rate_pct, na.rm = TRUE),
n = n(),
.groups = "drop"
) %>%
arrange(mean_drop)
print(model_predictions)
# Visualization
ggplot(model_predictions, aes(x = reorder(model_name, mean_drop), y = mean_drop)) +
geom_col(fill = "#3498db", alpha = 0.8) +
geom_errorbar(aes(ymin = mean_drop - sd_drop, ymax = mean_drop + sd_drop),
width = 0.3, alpha = 0.6) +
labs(
title = "Average Drop Rate by Model (All Conditions)",
subtitle = "Error bars show Â± 1 SD",
x = "Model",
y = "Mean Drop Rate (%)"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
fps_list <- sort(unique(device_performance$fps_target))
for (current_fps in fps_list) {
p <- device_performance %>%
filter(fps_target == current_fps) %>%
ggplot(aes(x = model_name, y = avg_latency_ms, fill = mode)) +
geom_boxplot(alpha = 0.7, outlier.shape = NA) +
geom_jitter(position = position_jitterdodge(jitter.width = 0.1), size = 1, alpha = 0.5) +
facet_wrap(~resolution, scales = "free_y") +
labs(
title = paste("Performance Comparison at", current_fps, "FPS"),
subtitle = "Comparing Local vs. Offload execution across models",
x = "Model Name",
y = "Latency (ms)",
fill = "Mode"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p)
}
for (current_fps in fps_list) {
p <- device_performance %>%
filter(fps_target == current_fps) %>%
pivot_longer(cols = c(inference_ms, overhead_ms),
names_to = "component", values_to = "ms") %>%
ggplot(aes(x = mode, y = ms, fill = component)) +
geom_bar(stat = "summary", fun = "mean", position = "stack", width = 0.7) +
facet_grid(resolution ~ model_name) +
scale_fill_manual(
values = c("inference_ms" = "#27ae60", "overhead_ms" = "#e74c3c"),
labels = c("Inference", "Network/Transport Overhead")
) +
labs(
title = paste("Latency Breakdown at", current_fps, "FPS"),
subtitle = "Green = AI Work | Red = Network Tax",
x = "Execution Mode",
y = "Total End-to-End Latency (ms)",
fill = "Component"
) +
theme_minimal() +
theme(legend.position = "bottom")
print(p)
}
all_fps    <- sort(unique(device_performance$fps_target))
all_codecs <- unique(device_performance$codec)
all_tiers  <- sort(unique(device_performance$tier))
for (f in all_fps) {
for (c in all_codecs) {
for (t in all_tiers) {
plot_subset <- device_performance %>%
filter(fps_target == f, codec == c, tier == t)
if(nrow(plot_subset) == 0) next
# Latency plot
p_lat <- ggplot(plot_subset, aes(x = model_name, y = avg_latency_ms, fill = mode)) +
geom_bar(stat = "summary", fun = "mean", position = position_dodge(width = 0.8), width = 0.7) +
geom_jitter(position = position_dodge(width = 0.8), size = 1.2, alpha = 0.5) +
facet_wrap(~resolution, scales = "free_y") +
scale_fill_manual(values = c("Local" = "#2c3e50", "Offload" = "#27ae60")) +
labs(title = paste("Latency |", f, "FPS |", c, "|", t),
y = "Avg Latency (ms)", x = "Model") +
theme_minimal()
# Drop rate plot
p_drop <- ggplot(plot_subset, aes(x = model_name, y = drop_rate_pct, fill = mode)) +
geom_bar(stat = "summary", fun = "mean", position = position_dodge(width = 0.8), width = 0.7) +
geom_jitter(position = position_dodge(width = 0.8), size = 1, alpha = 0.4) +
facet_wrap(~resolution) +
scale_fill_manual(values = c("Local" = "#34495e", "Offload" = "#d35400")) +
scale_y_continuous(limits = c(0, 100)) +
labs(title = paste("Drop Rate |", f, "FPS |", c, "|", t),
y = "Drop Rate (%)", x = "Model") +
theme_minimal()
# Detection plot
p_det <- ggplot(plot_subset, aes(x = model_name, y = avg_detections, fill = mode)) +
geom_bar(stat = "summary", fun = "mean", position = position_dodge(width = 0.8), width = 0.7) +
geom_jitter(position = position_dodge(width = 0.8), size = 1.2, alpha = 0.5) +
facet_wrap(~resolution) +
scale_fill_manual(values = c("Local" = "#2c3e50", "Offload" = "#8e44ad")) +
labs(
title = paste("Avg Detections |", f, "FPS"),
subtitle = paste("Codec:", c, "| Quality Tier:", t),
x = "AI Model",
y = "Avg Detection Count per Frame",
fill = "Execution Mode"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Print plots
print(p_lat)
print(p_drop)
print(p_det)
# Save plots
file_base <- paste0("fps", f, "_", c, "_", t)
ggsave(paste0("plots/latency_", file_base, ".png"), p_lat, width = 10, height = 6)
ggsave(paste0("plots/drops_", file_base, ".png"), p_drop, width = 10, height = 6)
ggsave(paste0("plots/det_", file_base, ".png"), p_det, width = 10, height = 6)
message("Saved plots for: ", file_base)
}
}
}
**Model Performance:**
